#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
- å®šæœŸçš„ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
- å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç®¡ç†
"""

import sqlite3
import json
import os
import time
from datetime import datetime, timedelta
from pathlib import Path
import threading

class BackupScheduler:
    """è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""
    
    def __init__(self, db_path, backup_dir, interval_seconds=300, max_backups=100):
        self.db_path = db_path
        self.backup_dir = Path(backup_dir)
        self.interval_seconds = interval_seconds  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5åˆ†
        self.max_backups = max_backups
        self.last_backup_time = time.time()
        self.thread = None
        self.running = False
    
    def backup_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’JSONãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        try:
            if not os.path.exists(self.db_path):
                print(f"âŒ Database not found: {self.db_path}")
                return False
            
            self.backup_dir.mkdir(exist_ok=True)
            
            conn = sqlite3.connect(str(self.db_path))
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å–å¾—ï¼ˆFTSãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é™¤å¤–ï¼‰
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' 
                AND name NOT LIKE 'sqlite_%'
                AND name NOT LIKE '%_fts%'
                AND name NOT LIKE '%_config'
                ORDER BY name
            """)
            tables = [row[0] for row in cursor.fetchall()]
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿
            backup_data = {
                'timestamp': datetime.now().isoformat(),
                'database': 'notion.db',
                'tables': {}
            }
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            for table in tables:
                cursor.execute(f'SELECT * FROM {table}')
                rows = cursor.fetchall()
                backup_data['tables'][table] = [dict(row) for row in rows]
            
            conn.close()
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = self.backup_dir / f'backup_{timestamp}.json'
            
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
            # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ latest.json ã«ã‚³ãƒ”ãƒ¼
            latest_file = self.backup_dir / 'latest.json'
            with open(latest_file, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
            self._cleanup_old_backups()
            
            print(f"âœ… Backup created: {backup_file.name} ({self._format_size(backup_file.stat().st_size)})")
            return True
            
        except Exception as e:
            print(f"âŒ Backup failed: {e}")
            return False
    
    def _cleanup_old_backups(self):
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆæœ€æ–°Nå€‹ã‚’ä¿æŒï¼‰"""
        try:
            backup_files = sorted(self.backup_dir.glob('backup_*.json'), reverse=True)
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚ˆã‚Šå¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            for old_backup in backup_files[self.max_backups:]:
                if old_backup.name != 'latest.json':
                    old_backup.unlink()
                    print(f"  ğŸ—‘ï¸ Deleted old backup: {old_backup.name}")
        except Exception as e:
            print(f"âš ï¸ Cleanup failed: {e}")
    
    def _format_size(self, size_bytes):
        """ãƒã‚¤ãƒˆæ•°ã‚’KBã‚„MBã®å˜ä½ã«å¤‰æ›"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f}KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f}MB"
    
    def should_backup(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        return current_time - self.last_backup_time > self.interval_seconds
    
    def backup_if_needed(self):
        """å¿…è¦ã«å¿œã˜ã¦ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        if self.should_backup():
            success = self.backup_database()
            if success:
                self.last_backup_time = time.time()
            return success
        return False
    
    def start_background_backup(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹"""
        if not self.running:
            self.running = True
            self.thread = threading.Thread(target=self._background_backup_loop, daemon=True)
            self.thread.start()
            print(f"âœ… Background backup scheduler started (interval: {self.interval_seconds}s)")
    
    def _background_backup_loop(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                self.backup_if_needed()
                time.sleep(10)  # 10ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
            except Exception as e:
                print(f"âš ï¸ Background backup error: {e}")
    
    def stop_background_backup(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
        print("âœ… Background backup scheduler stopped")


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_backup_scheduler = None

def init_backup_scheduler(app):
    """Flaskã‚¢ãƒ—ãƒªã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–"""
    global _backup_scheduler
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    db_path = os.path.join(base_dir, 'notion.db')
    backup_dir = os.path.join(base_dir, 'backups')
    
    # 300ç§’ï¼ˆ5åˆ†ï¼‰ã”ã¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€æœ€æ–°100å€‹ã‚’ä¿æŒ
    _backup_scheduler = BackupScheduler(
        db_path=db_path,
        backup_dir=backup_dir,
        interval_seconds=300,
        max_backups=100
    )
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    _backup_scheduler.start_background_backup()
    
    # ã‚¢ãƒ—ãƒªã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’åœæ­¢
    def shutdown():
        _backup_scheduler.stop_background_backup()
    
    app.teardown_appcontext(lambda exc: shutdown())

def trigger_backup():
    """æ‰‹å‹•ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ãƒˆãƒªã‚¬ãƒ¼"""
    global _backup_scheduler
    if _backup_scheduler:
        return _backup_scheduler.backup_database()
    return False
